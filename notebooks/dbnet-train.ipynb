{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-01-16T00:28:34.69768Z","iopub.status.busy":"2022-01-16T00:28:34.697267Z","iopub.status.idle":"2022-01-16T00:28:36.960963Z","shell.execute_reply":"2022-01-16T00:28:36.959849Z","shell.execute_reply.started":"2022-01-16T00:28:34.69762Z"},"trusted":true},"outputs":[],"source":["#-------------------\n","# fixed params\n","#------------------\n","dim =512\n","mean = [103.939, 116.779, 123.68]\n","thresh_min=0.3\n","thresh_max=0.7\n","#----------------\n","# imports\n","#---------------\n","import tensorflow as tf\n","import random\n","import json\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","#from kaggle_datasets import KaggleDatasets\n","from glob import glob\n","from tqdm.auto import tqdm\n","\n","%matplotlib inline\n","#-------------"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","print(gpus)\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T00:28:36.965399Z","iopub.status.busy":"2022-01-16T00:28:36.965137Z","iopub.status.idle":"2022-01-16T00:28:42.635427Z","shell.execute_reply":"2022-01-16T00:28:42.634351Z","shell.execute_reply.started":"2022-01-16T00:28:36.96537Z"},"trusted":true},"outputs":[],"source":["#----------------------------------------------------------\n","# Detect hardware, return appropriate distribution strategy\n","#----------------------------------------------------------\n","# TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","    tf.config.optimizer.set_jit(True)\n","else:\n","    strategy = tf.distribute.get_strategy() \n","    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T00:28:42.637106Z","iopub.status.busy":"2022-01-16T00:28:42.636875Z","iopub.status.idle":"2022-01-16T00:28:43.200184Z","shell.execute_reply":"2022-01-16T00:28:43.199517Z","shell.execute_reply.started":"2022-01-16T00:28:42.63708Z"},"trusted":true},"outputs":[],"source":["#-------------\n","# GCS and files and synth\n","#-------------\n","def get_tfrecs(_path):\n","    gcs_pattern=os.path.join(_path,'*.tfrecord')\n","    file_paths = tf.io.gfile.glob(gcs_pattern)\n","    random.shuffle(file_paths)\n","    return file_paths\n","\n","# synth\n","#GCS_PATH = KaggleDatasets().get_gcs_path('dbnet-dataset')  \n","GCS_PATH=\"/backup/RAW/DET/DATA/synth/temp/tfrecords/synthtext/\"\n","_recs =get_tfrecs(GCS_PATH)\n","\n","train_recs=_recs[1:]\n","eval_recs =_recs[:1]\n","print(len(eval_recs),len(train_recs))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T00:28:43.202655Z","iopub.status.busy":"2022-01-16T00:28:43.202432Z","iopub.status.idle":"2022-01-16T00:28:43.223287Z","shell.execute_reply":"2022-01-16T00:28:43.222191Z","shell.execute_reply.started":"2022-01-16T00:28:43.202628Z"},"trusted":true},"outputs":[],"source":["def data_input_fn(recs): \n","    '''\n","      This Function generates data from gcs\n","    '''\n","    \n","    def _parser(example):\n","        feature ={  'image'      : tf.io.FixedLenFeature([],tf.string),\n","                    'gt'         : tf.io.FixedLenFeature([],tf.string),\n","                    'mask'       : tf.io.FixedLenFeature([],tf.string),\n","                    'thresh_map' : tf.io.FixedLenFeature([],tf.string),\n","                    'thresh_mask': tf.io.FixedLenFeature([],tf.string)\n","        }     \n","        ret={}\n","        parsed_example=tf.io.parse_single_example(example,feature)\n","        # image\n","        image_raw=parsed_example['image']\n","        image=tf.image.decode_png(image_raw,channels=3)\n","        image=tf.cast(image,tf.float32)\n","        \n","        r=image[..., 0] \n","        g=image[..., 1]\n","        b=image[..., 2]\n","        \n","        r=tf.subtract(r,mean[0])\n","        g=tf.subtract(r,mean[1])\n","        b=tf.subtract(r,mean[2])\n","        \n","        r=tf.reshape(r,(dim,dim,1))\n","        g=tf.reshape(g,(dim,dim,1))\n","        b=tf.reshape(b,(dim,dim,1))\n","        \n","        image=tf.concat([r,g,b], -1)\n","        image=image/255\n","        image=tf.reshape(image,[dim,dim,3])\n","        ret[\"image\"]=image\n","        # thresh_map\n","        thresh_map=parsed_example['thresh_map']\n","        thresh_map=tf.image.decode_png(thresh_map,channels=1)\n","        thresh_map=tf.cast(thresh_map,tf.float32)/255.0\n","        thresh_map=tf.reshape(thresh_map,(dim,dim))\n","        thresh_map= thresh_map * (thresh_max - thresh_min) + thresh_min\n","        ret[\"thresh_map\"]=thresh_map\n","        # thresh_mask\n","        thresh_mask=parsed_example['thresh_mask']\n","        thresh_mask=tf.image.decode_png(thresh_mask,channels=1)\n","        thresh_mask=tf.cast(thresh_mask,tf.float32)/255.0\n","        thresh_mask=tf.reshape(thresh_mask,(dim,dim))\n","        ret[\"thresh_mask\"]=thresh_mask\n","        # gt\n","        gt=parsed_example['gt']\n","        gt=tf.image.decode_png(gt,channels=1)\n","        gt=tf.cast(gt,tf.float32)/255.0\n","        gt=tf.reshape(gt,(dim,dim))\n","        ret[\"gt\"]=gt\n","        # mask\n","        mask=parsed_example['mask']\n","        mask=tf.image.decode_png(mask,channels=1)\n","        mask=tf.cast(mask,tf.float32)/255.0\n","        mask=tf.reshape(mask,(dim,dim))\n","        ret[\"mask\"]=mask\n","        return ret\n","\n","    dataset = tf.data.TFRecordDataset(recs)\n","    dataset = dataset.map(_parser)\n","    dataset = dataset.shuffle(2048,reshuffle_each_iteration=True)\n","    dataset = dataset.repeat()\n","    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n","    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T00:28:43.225529Z","iopub.status.busy":"2022-01-16T00:28:43.225172Z","iopub.status.idle":"2022-01-16T00:28:43.241324Z","shell.execute_reply":"2022-01-16T00:28:43.240549Z","shell.execute_reply.started":"2022-01-16T00:28:43.225494Z"},"trusted":true},"outputs":[],"source":["#-------------------------\n","# train and data paras\n","#-----------------------\n","EPOCHS          = 100\n","if strategy.num_replicas_in_sync==1:\n","    BATCH_SIZE = 16\n","else:\n","    BATCH_SIZE = 128 * strategy.num_replicas_in_sync\n","\n","STEPS_PER_EPOCH = (len(train_recs))*1024//BATCH_SIZE\n","EVAL_STEPS      = (len(eval_recs)*1024)//BATCH_SIZE\n","print(\"Steps:\",STEPS_PER_EPOCH)\n","print(\"Eval Steps:\",EVAL_STEPS)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T00:28:43.24341Z","iopub.status.busy":"2022-01-16T00:28:43.243106Z","iopub.status.idle":"2022-01-16T00:29:29.97712Z","shell.execute_reply":"2022-01-16T00:29:29.976148Z","shell.execute_reply.started":"2022-01-16T00:28:43.243367Z"},"trusted":true},"outputs":[],"source":["#-----------------------\n","# visual\n","#-----------------------\n","train_ds  =   data_input_fn(train_recs)\n","eval_ds   =   data_input_fn(eval_recs)\n","for ret in eval_ds.take(1):\n","    for k,v in ret.items():\n","        print(k)\n","        data=np.squeeze(v[0])\n","        plt.imshow(data)\n","        plt.show()\n","        print(f'{k} Batch Shape:',v.shape)\n","        "]},{"cell_type":"markdown","metadata":{},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T00:29:29.979942Z","iopub.status.busy":"2022-01-16T00:29:29.979571Z","iopub.status.idle":"2022-01-16T00:29:30.005461Z","shell.execute_reply":"2022-01-16T00:29:30.00434Z","shell.execute_reply.started":"2022-01-16T00:29:29.979883Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras as K\n","from tensorflow.keras import layers as KL\n","\n","def balanced_crossentropy_loss(pred, gt, mask, negative_ratio=3.):\n","    pred = pred[..., 0]\n","    positive_mask = (gt * mask)\n","    negative_mask = ((1 - gt) * mask)\n","    positive_count = tf.reduce_sum(positive_mask)\n","    negative_count = tf.reduce_min([tf.reduce_sum(negative_mask), positive_count * negative_ratio])\n","    # loss_fun = tf.losses.BinaryCrossentropy()\n","    # loss = loss_fun(gt, pred)\n","    # loss = K.losses.binary_crossentropy(gt, pred)\n","    loss = K.backend.binary_crossentropy(gt, pred)\n","    positive_loss = loss * positive_mask\n","    negative_loss = loss * negative_mask\n","    negative_loss, _ = tf.nn.top_k(tf.reshape(negative_loss, (-1,)), tf.cast(negative_count, tf.int32))\n","\n","    balanced_loss = (tf.reduce_sum(positive_loss) + tf.reduce_sum(negative_loss)) / (positive_count + negative_count + 1e-6)\n","    return balanced_loss, loss\n","\n","\n","def dice_loss(pred, gt, mask, weights):\n","    \"\"\"\n","    Args:\n","        pred: (b, h, w, 1)\n","        gt: (b, h, w)\n","        mask: (b, h, w)\n","        weights: (b, h, w)\n","    Returns:\n","    \"\"\"\n","    pred = pred[..., 0]\n","    weights = (weights - tf.reduce_min(weights)) / (tf.reduce_max(weights) - tf.reduce_min(weights) + 1e-6) + 1.\n","    mask = mask * weights\n","    intersection = tf.reduce_sum(pred * gt * mask)\n","    union = tf.reduce_sum(pred * mask) + tf.reduce_sum(gt * mask) + 1e-6\n","    loss = 1 - 2.0 * intersection / union\n","    return loss\n","\n","\n","def l1_loss(pred, gt, mask):\n","    pred = pred[..., 0]\n","    mask_sum = tf.reduce_sum(mask)\n","    loss = K.backend.switch(mask_sum > 0, tf.reduce_sum(tf.abs(pred - gt) * mask) / (mask_sum + 1e-6), tf.constant(0.))\n","    return loss\n","\n","\n","def compute_cls_acc(pred, gt, mask):\n","\n","    zero = tf.zeros_like(pred, tf.float32)\n","    one = tf.ones_like(pred, tf.float32)\n","\n","    pred = tf.where(pred < 0.3, x=zero, y=one)\n","    acc = tf.reduce_mean(tf.cast(tf.equal(pred * mask, gt * mask), tf.float32))\n","\n","    return acc\n","\n","\n","def db_loss(args, alpha=5.0, beta=10.0, ohem_ratio=3.0):\n","    input_gt, input_mask, input_thresh, input_thresh_mask, binarize_map, thresh_binary, threshold_map = args\n","\n","    threshold_loss = l1_loss(threshold_map, input_thresh, input_thresh_mask)\n","    binarize_loss, dice_loss_weights = balanced_crossentropy_loss(binarize_map, input_gt, input_mask, negative_ratio=ohem_ratio)\n","    thresh_binary_loss = dice_loss(thresh_binary, input_gt, input_mask, dice_loss_weights)\n","\n","    model_loss = alpha * binarize_loss + beta * threshold_loss + thresh_binary_loss\n","    return model_loss\n","\n","\n","def db_acc(args):\n","    input_gt, input_mask, binarize_map, thresh_binary = args\n","    binarize_acc = compute_cls_acc(binarize_map, input_gt, input_mask)\n","    thresh_binary_acc = compute_cls_acc(thresh_binary, input_gt, input_mask)\n","    return binarize_acc, thresh_binary_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T00:29:30.007579Z","iopub.status.busy":"2022-01-16T00:29:30.007284Z","iopub.status.idle":"2022-01-16T00:29:30.055575Z","shell.execute_reply":"2022-01-16T00:29:30.054611Z","shell.execute_reply.started":"2022-01-16T00:29:30.007543Z"},"trusted":true},"outputs":[],"source":["def DBNet(k=50,\n","          dim=512,\n","          outs=[\"conv2_block3_out\",\n","                \"conv3_block4_out\",\n","                \"conv4_block6_out\",\n","                \"conv5_block3_out\"]):\n","    # input layer\n","    input_image = KL.Input(shape=[dim,dim, 3], name='image')\n","\n","    backbone = K.applications.resnet50.ResNet50(input_tensor=input_image,weights='imagenet',include_top=False)\n","    C2, C3, C4, C5 = [backbone.get_layer(out).output for out in outs]\n","\n","    # in2\n","    in2 = KL.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_normal', name='in2')(C2)\n","    in2 = KL.BatchNormalization()(in2)\n","    in2 = KL.ReLU()(in2)\n","    # in3\n","    in3 = KL.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_normal', name='in3')(C3)\n","    in3 = KL.BatchNormalization()(in3)\n","    in3 = KL.ReLU()(in3)\n","    # in4\n","    in4 = KL.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_normal', name='in4')(C4)\n","    in4 = KL.BatchNormalization()(in4)\n","    in4 = KL.ReLU()(in4)\n","    # in5\n","    in5 = KL.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_normal', name='in5')(C5)\n","    in5 = KL.BatchNormalization()(in5)\n","    in5 = KL.ReLU()(in5)\n","\n","    # P5\n","    P5 = KL.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(in5)\n","    P5 = KL.BatchNormalization()(P5)\n","    P5 = KL.ReLU()(P5)\n","    P5 = KL.UpSampling2D(size=(8, 8))(P5)\n","    # P4\n","    out4 = KL.Add()([in4, KL.UpSampling2D(size=(2, 2))(in5)])\n","    P4 = KL.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(out4)\n","    P4 = KL.BatchNormalization()(P4)\n","    P4 = KL.ReLU()(P4)\n","    P4 = KL.UpSampling2D(size=(4, 4))(P4)\n","    # P3\n","    out3 = KL.Add()([in3, KL.UpSampling2D(size=(2, 2))(out4)])\n","    P3 = KL.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(out3)\n","    P3 = KL.BatchNormalization()(P3)\n","    P3 = KL.ReLU()(P3)\n","    P3 = KL.UpSampling2D(size=(2, 2))(P3)\n","    # P2\n","    out2 = KL.Add()([in2, KL.UpSampling2D(size=(2, 2))(out3)])\n","    P2 = KL.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(out2)\n","    P2 = KL.BatchNormalization()(P2)\n","    P2 = KL.ReLU()(P2)\n","\n","    fuse = KL.Concatenate()([P2, P3, P4, P5])\n","\n","    # binarize map\n","    p = KL.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', use_bias=False)(fuse)\n","    p = KL.BatchNormalization()(p)\n","    p = KL.ReLU()(p)\n","    p = KL.Conv2DTranspose(64, (2, 2), strides=(2, 2), kernel_initializer='he_normal', use_bias=False)(p)\n","    p = KL.BatchNormalization()(p)\n","    p = KL.ReLU()(p)\n","    binarize_map  = KL.Conv2DTranspose(1, (2, 2), strides=(2, 2), kernel_initializer='he_normal',activation='sigmoid', name='binarize_map')(p)\n","\n","    # threshold map\n","    t = KL.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', use_bias=False)(fuse)\n","    t = KL.BatchNormalization()(t)\n","    t = KL.ReLU()(t)\n","    t = KL.Conv2DTranspose(64, (2, 2), strides=(2, 2), kernel_initializer='he_normal', use_bias=False)(t)\n","    t = KL.BatchNormalization()(t)\n","    t = KL.ReLU()(t)\n","    threshold_map  = KL.Conv2DTranspose(1, (2, 2), strides=(2, 2), kernel_initializer='he_normal',activation='sigmoid', name='threshold_map')(t)\n","\n","    # thresh binary map\n","    thresh_binary = KL.Lambda(lambda x: 1 / (1 + tf.exp(-k * (x[0] - x[1]))))([binarize_map, threshold_map])\n","\n","    input_gt = KL.Input(shape=[dim,dim], name='gt')\n","    input_mask = KL.Input(shape=[dim,dim], name='mask')\n","    input_thresh = KL.Input(shape=[dim,dim], name='thresh_map')\n","    input_thresh_mask = KL.Input(shape=[dim,dim], name='thresh_mask')\n","\n","    loss_layer = KL.Lambda(db_loss, name='db_loss')([input_gt, input_mask, input_thresh, input_thresh_mask, binarize_map, thresh_binary, threshold_map])\n","\n","    db_model = K.Model(inputs=[input_image, input_gt, input_mask, input_thresh, input_thresh_mask],outputs=[loss_layer])\n","\n","    loss_names = [\"db_loss\"]\n","    for layer_name in loss_names:\n","        layer = db_model.get_layer(layer_name)\n","        db_model.add_loss(layer.output)\n","    return db_model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T00:29:30.057841Z","iopub.status.busy":"2022-01-16T00:29:30.05749Z","iopub.status.idle":"2022-01-16T00:29:43.951106Z","shell.execute_reply":"2022-01-16T00:29:43.949859Z","shell.execute_reply.started":"2022-01-16T00:29:30.057798Z"},"trusted":true},"outputs":[],"source":["with strategy.scope():\n","    model=DBNet()\n","    model.compile(optimizer=K.optimizers.Adam(),loss=[None] * len(model.output.shape))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T00:29:43.952802Z","iopub.status.busy":"2022-01-16T00:29:43.95253Z","iopub.status.idle":"2022-01-16T00:29:43.964028Z","shell.execute_reply":"2022-01-16T00:29:43.963017Z","shell.execute_reply.started":"2022-01-16T00:29:43.952769Z"},"trusted":true},"outputs":[],"source":["# reduces learning rate on plateau\n","lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1,\n","                                                  cooldown= 10,\n","                                                  patience=3,\n","                                                  verbose =1,\n","                                                  min_lr=0.1e-7)\n","# early stopping\n","early_stopping = tf.keras.callbacks.EarlyStopping(patience=1, \n","                                                  verbose=1, \n","                                                  mode = 'auto') \n","\n","\n","class SaveBestModel(tf.keras.callbacks.Callback):\n","    def __init__(self):\n","        self.best = float('inf')\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        metric_value = logs['val_loss']\n","        if metric_value < self.best:\n","            print(f\"Loss Improved epoch:{epoch} from {self.best} to {metric_value}\")\n","            self.best = metric_value\n","            inp=self.model.get_layer(\"image\").input\n","            out=self.model.get_layer('binarize_map').output\n","            net=tf.keras.Model(inputs=inp,outputs=out)\n","            net.save_weights(f\"dbnet.h5\")\n","            print(\"Saved Best Weights\")\n","    def set_model(self, model):\n","        self.model = model\n","            \n","model_save=SaveBestModel()\n","model_save.set_model(model)\n","callbacks= [lr_reducer,early_stopping,model_save]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T00:29:43.965569Z","iopub.status.busy":"2022-01-16T00:29:43.965329Z","iopub.status.idle":"2022-01-16T00:30:15.943606Z","shell.execute_reply":"2022-01-16T00:30:15.941742Z","shell.execute_reply.started":"2022-01-16T00:29:43.965542Z"},"trusted":true},"outputs":[],"source":["EPOCHS=5\n","history=model.fit(train_ds,\n","                  epochs=EPOCHS,\n","                  steps_per_epoch=STEPS_PER_EPOCH,\n","                  verbose=1,\n","                  validation_data=eval_ds,\n","                  validation_steps=EVAL_STEPS, \n","                  callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
