{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f64ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def create_dir(base,ext):\n",
    "    '''\n",
    "        creates a directory extending base\n",
    "        args:\n",
    "            base    =   base path \n",
    "            ext     =   the folder to create\n",
    "    '''\n",
    "    _path=os.path.join(base,ext)\n",
    "    if not os.path.exists(_path):\n",
    "        os.mkdir(_path)\n",
    "    return _path\n",
    "\n",
    "\n",
    "save_path=\"/backup/RAW/DET/\"\n",
    "save_path=create_dir(save_path,\"boise_state\")\n",
    "img_dir=create_dir(save_path,\"images\")\n",
    "gt_dir=create_dir(save_path,\"gts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eac799",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def extract_info(_dir,coords,fmt):\n",
    "    '''\n",
    "        extracts information from boise-state annotations\n",
    "    '''\n",
    "    img_paths=[img_path for img_path in glob(os.path.join(_dir,f\"*.{fmt}\"))]\n",
    "    liness=[]\n",
    "    words=[]\n",
    "    comps=[]\n",
    "    chars=[]\n",
    "    xmins=[]\n",
    "    ymins=[]\n",
    "    xmaxs=[]\n",
    "    ymaxs=[]\n",
    "    _paths=[]\n",
    "    # images\n",
    "    for img_path in tqdm(img_paths):\n",
    "        base=img_path.split(\".\")[0]\n",
    "        # text path\n",
    "        _iden=os.path.basename(img_path).split(\".\")[0]\n",
    "        text_path=os.path.join(_dir,coords,f\"{_iden}.txt\")\n",
    "        with open(text_path,\"r\") as tf:\n",
    "            lines=tf.readlines()\n",
    "        for line in lines:\n",
    "            parts=line.split()\n",
    "            if len(parts)>4:\n",
    "                line_num=parts[0].replace(\"\\ufeff\",\"\")\n",
    "                word_num=parts[1]\n",
    "                label=parts[2]\n",
    "                data=parts[3]\n",
    "                x,y,w,h=[int(i) for i in parts[-1].split(\",\")]\n",
    "                liness.append(line_num)\n",
    "                words.append(word_num)\n",
    "                chars.append(label)\n",
    "                xmins.append(x)\n",
    "                ymins.append(y)\n",
    "                xmaxs.append(x+w)\n",
    "                ymaxs.append(y+h)\n",
    "                _paths.append(img_path)\n",
    "                comps.append(data)\n",
    "    df=pd.DataFrame({\"line\":liness,\n",
    "                     \"word\":words,\n",
    "                     \"char\":chars,\n",
    "                     \"comp\":comps,\n",
    "                     \"xmin\":xmins,\n",
    "                     \"ymin\":ymins,\n",
    "                     \"xmax\":xmaxs,\n",
    "                     \"ymax\":ymaxs,\n",
    "                     \"image\":_paths})\n",
    "    return df\n",
    "\n",
    "def check_missing(_dir,coords,fmt):\n",
    "    '''\n",
    "        checks for missing data\n",
    "    '''\n",
    "    img_paths=[img_path for img_path in glob(os.path.join(_dir,f\"*.{fmt}\"))]\n",
    "    txt_paths=[txt_path for txt_path in glob(os.path.join(_dir,coords,\"*.txt\"))]\n",
    "    # error check\n",
    "    for img_path in tqdm(img_paths):\n",
    "        if \"jpg\" in img_path:\n",
    "            _iden=os.path.basename(img_path).split(\".\")[0]\n",
    "            txt_path=os.path.join(_dir,coords,f\"{_iden}.txt\")\n",
    "            if not os.path.exists(txt_path):\n",
    "                print(img_path)\n",
    "                for txt in txt_paths:\n",
    "                    if _iden in txt:\n",
    "                        print(txt)\n",
    "                        niden=os.path.basename(txt).split('.')[0]\n",
    "                        print(f\"RENAME:{_iden} to {niden}\")\n",
    "                        os.rename(os.path.join(_dir,f\"{_iden}.{fmt}\"),\n",
    "                                  os.path.join(_dir,f\"{niden}.{fmt}\"))\n",
    "                        \n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf29656",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_txt_path=\"/backup/RAW/BanglaC/README.txt\"\n",
    "base_path=os.path.dirname(readme_txt_path)\n",
    "print(base_path)\n",
    "assert len(os.listdir(base_path))==5,\"WRONG PATH FOR README.txt\"\n",
    "\n",
    "os.listdir(base_path)\n",
    "dfs=[]\n",
    "# ## 1.Camera\n",
    "_dir=os.path.join(base_path,'1. Camera','1. Essay')\n",
    "coords='Character Coordinates_a'\n",
    "fmt=\"jpg\"\n",
    "check_missing(_dir,coords,fmt)\n",
    "dfs.append(extract_info(_dir,coords,fmt))\n",
    "# ## 2. Scan\n",
    "_dir=os.path.join(base_path,'2. Scan','1. Essay')\n",
    "coords='Character Coordinates_a'\n",
    "fmt=\"tif\"\n",
    "check_missing(_dir,coords,fmt)\n",
    "dfs.append(extract_info(_dir,coords,fmt))\n",
    "# # 3. Conjunct\n",
    "_dir=os.path.join(base_path,'3. Conjunct')\n",
    "coords='Character Coordinates'\n",
    "fmt=\"tif\"\n",
    "check_missing(_dir,coords,fmt)\n",
    "dfs.append(extract_info(_dir,coords,fmt))\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "df   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import cv2\n",
    "for img_path in tqdm(df.image.unique()):\n",
    "    img=cv2.imread(img_path)\n",
    "    base_=os.path.basename(img_path).split(\".\")[0]\n",
    "    img_dst=os.path.join(img_dir,f\"{base_}.jpg\")\n",
    "    cv2.imwrite(img_dst,img)\n",
    "    \n",
    "    idf=df.loc[df.image==img_path]\n",
    "\n",
    "    box_text_list = []\n",
    "    for line in idf.line.unique():\n",
    "        linedf=idf.loc[idf.line==line]\n",
    "        for word in linedf.word.unique():\n",
    "            wdf=linedf.loc[linedf.word==word]\n",
    "            # word\n",
    "            x1=int(min(wdf.xmin.tolist()))\n",
    "            x2=int(max(wdf.xmax.tolist()))\n",
    "\n",
    "            y1=int(min(wdf.ymin.tolist()))\n",
    "            y2=int(max(wdf.ymax.tolist()))\n",
    "\n",
    "            label=\"\".join(wdf.comp.tolist())\n",
    "            box=[x1,y1,x2,y1,x2,y2,x1,y2]\n",
    "            if label==\"*\":\n",
    "                text = \"###\"\n",
    "            else:\n",
    "                text=label\n",
    "\n",
    "            box_text_list.append(','.join(map(str, box)))\n",
    "            box_text_list.append(',')\n",
    "            box_text_list.append(text)\n",
    "            box_text_list.append('\\n')\n",
    "    gts_text_file=os.path.join(gt_dir,f\"{base_}.txt\")\n",
    "    with  open(gts_text_file, \"w\") as file:\n",
    "        makeitastring = ''.join(map(str, box_text_list))\n",
    "        file.write(makeitastring)\n",
    "        file.close()    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff81754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangla",
   "language": "python",
   "name": "bangla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
